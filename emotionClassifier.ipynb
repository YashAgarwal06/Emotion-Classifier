{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NxZ3t0CHJ5G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from numpy import genfromtxt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = genfromtxt('fer2013.csv', delimiter=',', dtype=str)\n",
        "trainingX = []\n",
        "trainingY = []\n",
        "testingX = []\n",
        "testingY = []\n",
        "for i in range(1,len(data)):\n",
        "  if(data[i][2] == 'Training'):\n",
        "    tmp = [0,0,0,0,0,0,0]\n",
        "    tmp[int(data[i][0])] = 1\n",
        "    trainingY.append(tmp)\n",
        "    tmp = np.reshape(data[i][1].split(), (48,48))\n",
        "    tmpArr = []\n",
        "    for x in range(48):\n",
        "      aks = []\n",
        "      for y in range(48):\n",
        "        aks.append(float(tmp[x][y]))\n",
        "      tmpArr.append(aks)\n",
        "    trainingX.append([tmpArr])\n",
        "  else:\n",
        "    tmp = [0,0,0,0,0,0,0]\n",
        "    tmp[int(data[i][0])] = 1\n",
        "    testingY.append(tmp)\n",
        "    tmp = np.reshape(data[i][1].split(), (48,48))\n",
        "    tmpArr = []\n",
        "    for x in range(48):\n",
        "      aks = []\n",
        "      for y in range(48):\n",
        "        aks.append(float(tmp[x][y]))\n",
        "      tmpArr.append(aks)\n",
        "    testingX.append([tmpArr])\n"
      ],
      "metadata": {
        "id": "ZJISYSOrHZBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingX = np.array(trainingX)\n",
        "testingX = np.array(testingX)\n",
        "trainingY = np.array(trainingY)\n",
        "testingY = np.array(testingY)\n",
        "valX = trainingX[0:4000]\n",
        "valY = trainingY[0:4000]\n",
        "trainingX = trainingX[4000:]\n",
        "trainingY = trainingY[4000:]"
      ],
      "metadata": {
        "id": "UHWiAEdXNxHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingX = torch.tensor(trainingX, requires_grad=False).double()\n",
        "trainingY = torch.tensor(trainingY, requires_grad=False).double()\n",
        "testingX = torch.tensor(testingX, requires_grad=False).double()\n",
        "testingY = torch.tensor(testingY, requires_grad=False).double()\n",
        "valX = torch.tensor(valX, requires_grad=False).double()\n",
        "valY = torch.tensor(valY, requires_grad=False).double()"
      ],
      "metadata": {
        "id": "7NXtPaxrYodZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainingX.shape)\n",
        "print(trainingY.shape)\n",
        "print(testingX.shape)\n",
        "print(testingY.shape)"
      ],
      "metadata": {
        "id": "-34drg-eY3YN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3561a73-7149-40db-d170-827341ae5813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([24709, 1, 48, 48])\n",
            "torch.Size([24709, 7])\n",
            "torch.Size([7178, 1, 48, 48])\n",
            "torch.Size([7178, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in range(5):\n",
        "  plt.imshow(trainingX[i][0],cmap='gray', vmin=0, vmax=255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "yOepXs8BaMSK",
        "outputId": "b02531d9-568b-4024-8d67-91236dff488f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_emotion = ['Angry', 'Disgust','Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,256,3)\n",
        "    self.batchNorm1 = nn.BatchNorm2d(256)\n",
        "    self.conv2 = nn.Conv2d(256,256,3)\n",
        "    self.batchNorm2 = nn.BatchNorm2d(256)\n",
        "    self.conv3 = nn.Conv2d(256,128,3)\n",
        "    self.batchNorm3 = nn.BatchNorm2d(128)\n",
        "    self.conv4 = nn.Conv2d(128,128,3)\n",
        "    self.batchNorm4 = nn.BatchNorm2d(128)\n",
        "    self.conv5 = nn.Conv2d(128,64,3)\n",
        "    self.batchNorm5 = nn.BatchNorm2d(64)\n",
        "    self.conv6 = nn.Conv2d(64,64,3)\n",
        "    self.batchNorm6 = nn.BatchNorm2d(64)\n",
        "\n",
        "\n",
        "    self.lin1 = nn.Linear(1600,512)\n",
        "    self.batchNorm7 = nn.BatchNorm1d(512)\n",
        "    self.lin2 = nn.Linear(512, 256)\n",
        "    self.batchNorm8 = nn.BatchNorm1d(256)\n",
        "    self.lin3 = nn.Linear(256,128)\n",
        "    self.batchNorm9 = nn.BatchNorm1d(128)\n",
        "    self.lin4 = nn.Linear(128,7)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.pool = nn.MaxPool2d(2, stride=(2,2))\n",
        "\n",
        "    self.flatten = nn.Flatten(1)\n",
        "\n",
        "  def forward(self,x):\n",
        "     x = self.relu(self.batchNorm1(self.conv1(x)))\n",
        "     x = self.relu(self.batchNorm2(self.conv2(x)))\n",
        "     x = self.pool(x)\n",
        "     x = self.relu(self.batchNorm3(self.conv3(x)))\n",
        "     x = self.relu(self.batchNorm4(self.conv4(x)))\n",
        "     x = self.pool(x)\n",
        "     x = self.relu(self.batchNorm5(self.conv5(x)))\n",
        "     x = self.relu(self.batchNorm6(self.conv6(x)))\n",
        "     x = self.flatten(x)\n",
        "     x = self.relu(self.batchNorm7(self.lin1(x)))\n",
        "     x = self.relu(self.batchNorm8(self.lin2(x)))\n",
        "     x = self.relu(self.batchNorm9(self.lin3(x)))\n",
        "     return self.lin4(x)\n",
        " \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "VXQkX2PiHqsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "softmax = nn.Softmax()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().double().to(device)\n",
        "trainingX = trainingX\n",
        "trainingY = trainingY\n",
        "testingX = testingX\n",
        "testingY = testingY\n"
      ],
      "metadata": {
        "id": "YR4b9I80g_I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossFunc = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=3e-2)\n",
        "NUM_EPOCHS = 500\n",
        "BATCH_SIZE = 50\n",
        "NUM_BATCHES = int(len(trainingX)/BATCH_SIZE)\n",
        "lossHistory = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for batch in range(NUM_BATCHES):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(trainingX[batch*BATCH_SIZE:batch*BATCH_SIZE + BATCH_SIZE])\n",
        "    loss = lossFunc(y_pred, trainingY[batch*BATCH_SIZE:batch*BATCH_SIZE + BATCH_SIZE])\n",
        "    \n",
        "    #print(y_pred)\n",
        "    #print(trainingY[0:1])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #lossHistory.append(loss.tolist())\n",
        "  print(\"Training Loss: \" + str(loss))\n",
        "  total = len(valY)\n",
        "  wrong = 0\n",
        "  for i in range(len(valY)):\n",
        "    l1 = torch.round(softmax(model(valX[i:i+1].cuda())))\n",
        "    l2 = valY[i:i+1].cuda()\n",
        "    if(((l1-l2)**2).sum()!=0):\n",
        "      #print(\"Real: \" + str(l2))\n",
        "      #print(\"Guess: \" + str(l1))\n",
        "      wrong = wrong + 1\n",
        "  print(\"Validation Accuracy: \"+str((total-wrong)/total))\n",
        "#plt.plot(lossHistory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "V4uTNyfsFWB-",
        "outputId": "1baf38e8-b1d2-4b0e-ba12-8010c1931597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-350136590a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_BATCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-0cb1c38d0069>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchNorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchNorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m      \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchNorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluates accuracy on testing set\n",
        "total = len(testingY)\n",
        "wrong = 0\n",
        "for i in range(len(testingY)):\n",
        "  l1 = torch.round(softmax(model(testingX[i:i+1].cuda())))\n",
        "  l2 = testingY[i:i+1].cuda()\n",
        "  if(((l1-l2)**2).sum()!=0):\n",
        "    #print(\"Real: \" + str(l2))\n",
        "    #print(\"Guess: \" + str(l1))\n",
        "    wrong = wrong + 1\n",
        "print((total-wrong)/total)"
      ],
      "metadata": {
        "id": "Z7S-OlEZJwec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluates accuracy on training set\n",
        "total = len(trainingY)\n",
        "wrong = 0\n",
        "for i in range(len(trainingY)):\n",
        "  l1 = torch.round(softmax(model(trainingX[i:i+1])))\n",
        "  l2 = trainingY[i:i+1]\n",
        "  if(((l1-l2)**2).sum()!=0):\n",
        "    wrong = wrong + 1\n",
        "print((total-wrong)/total)"
      ],
      "metadata": {
        "id": "bHRHQVXZNIO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluates accuracy on validation set\n",
        "total = len(valY)\n",
        "wrong = 0\n",
        "for i in range(len(valY)):\n",
        "  l1 = torch.round(softmax(model(valX[i:i+1])))\n",
        "  l2 = valY[i:i+1]\n",
        "  if(((l1-l2)**2).sum()!=0):\n",
        "    wrong = wrong + 1\n",
        "print((total-wrong)/total)"
      ],
      "metadata": {
        "id": "aIuyooCl-rqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}